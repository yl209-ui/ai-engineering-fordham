{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ðŸŽ“ **Professor**: Apostolos Filippas\n",
    "\n",
    "### ðŸ“˜ **Class**: AI Engineering\n",
    "\n",
    "### ðŸ“‹ **Topic**: You Can Just Build Things\n",
    "\n",
    "ðŸš« **Note**: You are not allowed to share the contents of this notebook with anyone outside this class without written permission by the professor.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome!\n",
    "\n",
    "In our firstfour lectures, we've covered how\n",
    "1. We can call LLMs via APIs and get structured responses\n",
    "2. We can build lexical search with BM25\n",
    "3. We can build semantic search with embeddings\n",
    "4. We can combine lexical and semantic search into hybrid search\n",
    "\n",
    "Today you will put it all together by building a Retrieval Augmented Generation (RAG) system.\n",
    "- This is a question-answering bot that can answer questions about Fordham University\n",
    "- You will use real data scraped from the Fordham website.\n",
    "\n",
    "\n",
    "Your RAG pipeline will look like this:\n",
    "\n",
    "```\n",
    "User Question\n",
    "     â†“\n",
    "1. RETRIEVE: Find relevant documents (search!)\n",
    "     â†“\n",
    "2. AUGMENT: Stuff those documents into a prompt\n",
    "     â†“\n",
    "3. GENERATE: Ask an LLM to answer using the context\n",
    "     â†“\n",
    "Answer\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Look at your data\n",
    "\n",
    "In `data/fordham-website.zip` you'll find **~9,500 Markdown files** scraped from Fordham's website. Each file is one page â€” admissions info, program descriptions, faculty pages, financial aid, campus life, and more.\n",
    "\n",
    "Your task: **look at the data**\n",
    "- The first step in any AI engineering or data science project should always be to familiarize yourself with the data.\n",
    "- I cannot stress this enough.. without this step, it's hard to build anything useful.\n",
    "\n",
    "Tips:\n",
    "- Unzip the archive and look at some of the files. \n",
    "- Open a few in a text editor. \n",
    "- Get a feel for what you're working with.\n",
    "- The first line of every file is always the **URL** of the page it was scraped from. The rest is the page content converted to Markdown. Here's an example â€” `gabelli-school-of-business_veterans.md`:\n",
    "\n",
    "```markdown\n",
    "https://www.fordham.edu/gabelli-school-of-business/veterans\n",
    "\n",
    "# Military Veterans & Active Duty Members of the Military\n",
    "\n",
    "## Transform Your Knowledge & Skills Into a Business Career for the Future\n",
    "\n",
    "As a veteran or an active duty member of the United States Armed Services,\n",
    "you have gained or are currently acquiring the invaluable organizational,\n",
    "leadership, analytics, and technical knowledge and skills that hiring\n",
    "managers seek. These transferrable skills provide a major advantage in\n",
    "emerging, business-related industries where innovation, a global mind-set,\n",
    "and the ability to lead individuals and teams in the continuously evolving\n",
    "work environment, are critical for success.\n",
    "\n",
    "By completing a graduate or undergraduate business degree at the Gabelli\n",
    "School of Business, you can prepare for a lifelong career in some of\n",
    "today's fastest-growing fields. ...\n",
    "\n",
    "### Study at a Top-Ranked, Military-Friendly University\n",
    "\n",
    "The Gabelli School of Business is part of Fordham University, the only\n",
    "New York City university to be among those ranked \"Best for Vets\" by\n",
    "Military Times. ...\n",
    "\n",
    "### Learn How the Yellow Ribbon Program Works\n",
    "\n",
    "The Yellow Ribbon GI Education Enhancement Program, or the Yellow Ribbon\n",
    "Program, is a part of the Post-9/11 Veterans Educational Assistance Act\n",
    "of 2008. ...\n",
    "```\n",
    "\n",
    "The filenames mirror the URL structure â€” underscores replace path separators (e.g. `gabelli-school-of-business_veterans.md` came from `/gabelli-school-of-business/veterans`). Some files are short (a few lines), others are quite long.\n",
    "\n",
    "- Once you've looked around, load the files into Python. Python's built-in `zipfile` module can read zip archives without extracting to disk. Load them into a list of dictionaries or a DataFrame with at least two fields: the filename (or a clean page name) and the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for your implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Chunk the Documents\n",
    "\n",
    "Some of the pages could be too long to embed as a single unit. Down the line, the pages may be too long to stuff into the LLM's prompt during the generation step. As such, most of the RAG systems will break down big documents into into smaller **chunks**.\n",
    "\n",
    "> ðŸ“š **TERM: Chunking**  \n",
    "> Splitting documents into smaller, self-contained pieces for embedding and retrieval. The goal is chunks that are small enough to be specific, but large enough to be meaningful.\n",
    "\n",
    "Your task: **write a function that splits each document into chunks.**\n",
    "\n",
    "Things to think about:\n",
    "- What's a reasonable chunk size? (Think about what fits in a prompt vs. what's too vague)\n",
    "- Should you split on sentences? Paragraphs? A fixed character/word count?\n",
    "- Should chunks overlap? What happens if an answer spans two chunks?\n",
    "- How do you keep track of which document each chunk came from? You may need that information down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for your implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Embed the Chunks\n",
    "\n",
    "Now we need to turn each chunk into a vector so we can search over them. You've done this before in Lecture 4.\n",
    "\n",
    "Your task: **embed all chunks using an embedding model.**\n",
    "\n",
    "Tips:\n",
    "- You could use a local model, or API model. What are the tradeoffs?\n",
    "- This will take a while if you do it serially. You might want to use async/batch.\n",
    "- Once you've created your embeddings, you may want to save them to disk so you don't have to redo this step every time\n",
    "- You'll need to embed queries with the **same model** at search time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for your implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Retrieve\n",
    "\n",
    "Now build the **R** in RAG. Given a user's question, find the most relevant chunks.\n",
    "\n",
    "Your task: **write a retrieval function that takes a question and returns the most relevant chunks.**\n",
    "\n",
    "Tips:\n",
    "- You can use lexical or semantic search or both!\n",
    "- How many chunks should you retrieve? Too few and you might miss the answer; too many and you'll overwhelm the LLM (and pay more tokens)\n",
    "- Try a few test questions and eyeball whether the retrieved chunks are relevant\n",
    "- Try a few questions and see what comes back. For example:\n",
    "  - \"What programs does the Gabelli School of Business offer?\"\n",
    "  - \"How do I apply for financial aid?\"\n",
    "  - \"Where is Fordham's campus?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your implementation here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Generate\n",
    "\n",
    "Now build the **G** in RAG. Take the retrieved chunks and pass them to an LLM along with the user's question.\n",
    "\n",
    "Your task: **write a function that takes a question and the retrieved chunks, builds a prompt, and calls an LLM to generate an answer.**\n",
    "\n",
    "Tips:\n",
    "- How should you structure the prompt? The LLM needs to know: (1) what is the context of the application, (2) what is the question, (3) what it should include in its answer\n",
    "- What should the LLM do if the context doesn't contain the answer?\n",
    "- Start with a cheap model; try a better one when you've figured out the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for your implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Wire everything together\n",
    "\n",
    "Combine the previous steps into a simple function that takes in a question and returns an answer.\n",
    "\n",
    "Your task: **write a `rag(question)` function that retrieves relevant chunks and generates an answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for your implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7. Evaluate, experiment and improve\n",
    "\n",
    "Your RAG system works â€” but there's always room to make it better. \n",
    "\n",
    "Your task: **evaluate, experiment, and improve your system**\n",
    "\n",
    "Tips:\n",
    "- How do you know that your system is working or that your changes are improving it?\n",
    "- Try different questions â€” where does it do well? Where does it struggle?\n",
    "- Adjust the number of retrieved chunks â€” what happens with more or fewer?\n",
    "- Try different chunking strategies â€” bigger chunks? Smaller? Overlap?\n",
    "- Try a different embedding model â€” does it change retrieval quality?\n",
    "- Improve the prompt â€” can you get better, more concise answers?\n",
    "- Add source attribution â€” can the system tell the user which pages the answer came from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for your implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 8. (Optional) Make it an app\n",
    "\n",
    "So far your RAG system lives inside a notebook. That's great for development â€” but nobody is going to use your Jupyter notebook to ask questions about Fordham. Let's turn it into a real web app.\n",
    "\n",
    "> ðŸ“š **TERM: Streamlit**  \n",
    "> A Python library that turns plain Python scripts into interactive web apps. You write Python â€” no HTML, CSS, or JavaScript â€” and Streamlit renders it as a web page with inputs, buttons, and formatted output. It's the fastest way to go from \"I have a function\" to \"I have a web app.\"\n",
    "\n",
    "Your task: **create a Streamlit app that lets a user type a question about Fordham and get an answer from your RAG system.**\n",
    "\n",
    "To get started:\n",
    "- Install it: `uv pip install streamlit` \n",
    "- A Streamlit app is just a `.py` file (not a notebook). Create something like `fordham_rag_app.py`\n",
    "- Run it: `streamlit run scripts/fordham_rag_app.py` â€” this opens a browser tab with your app\n",
    "\n",
    "Tips:\n",
    "- Check out the [Streamlit docs](https://docs.streamlit.io/) â€” the \"Get started\" tutorial is very short\n",
    "- Your best bet is to vibecode your way to this. You'll be surprised how fast you can get it up and running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "## What You Built\n",
    "\n",
    "| Step | What You Did | What It Does |\n",
    "|------|-------------|-------------|\n",
    "| **Load** | Read 9,500+ Fordham web pages | Get raw content |\n",
    "| **Chunk** | Split pages into smaller pieces | Make content searchable and promptable |\n",
    "| **Embed** | Turn chunks into vectors | Enable semantic search |\n",
    "| **Retrieve** | Find relevant chunks for a question | The **R** in RAG |\n",
    "| **Generate** | Ask an LLM to answer using the chunks | The **G** in RAG |\n",
    "| **RAG** | Wire it all together | Question in, answer out |\n",
    "\n",
    "## The Big Picture\n",
    "\n",
    "RAG is one of the most common patterns in AI engineering today. What you built here is the same core architecture behind tools like ChatGPT with search, Perplexity, enterprise Q&A bots, and more. The details get more sophisticated (vector databases, reranking, query rewriting, evaluation) but the pattern is the same:\n",
    "\n",
    "**Find relevant stuff â†’ give it to an LLM â†’ get an answer.**\n",
    "\n",
    "You can just build things."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ce)",
   "language": "python",
   "name": "ce"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
